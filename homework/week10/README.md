## 1. 什麼是「線性」？為何叫「代數」？

### 線性（Linearity）
一個運算 \(T\) 若滿足  
\[
T(au + bv) = aT(u) + bT(v)
\]  
則稱線性；它保持比例與可加性。

### 代數（Algebra）
線性代數研究向量、矩陣、線性變換，以及其運算規則，因此稱為「代數」。

---

## 2. 空間與向量空間

### 數學中的空間（Space）
空間＝元素集合＋定義其上的結構（如加法、距離、內積）。

### 向量空間（Vector Space）
能做「向量加法」與「數乘」，並滿足公理，因此被視為一種空間。

---

## 3. 矩陣與向量的關係

- 向量：座標表示。
- 矩陣：線性變換在特定基底下的座標表示。
- 矩陣的每欄＝基底向量經線性變換後的位置。

矩陣可表示旋轉、縮放、剪切、反射、投影等線性變換。

---

## 4. 矩陣如何表示 2D / 3D 的平移、縮放、旋轉？

### 2D 縮放
$$
\begin{bmatrix}
s_x & 0 \\
0 & s_y
\end{bmatrix}
$$

### 2D 旋轉
$$
\begin{bmatrix}
\cos\theta & -\sin\theta\\
\sin\theta & \cos\theta
\end{bmatrix}
$$

### 2D 平移（需齊次座標）
$$
\begin{bmatrix}
1 & 0 & t_x\\
0 & 1 & t_y\\
0 & 0 & 1
\end{bmatrix}
$$

---

## 5. 行列式的意義、遞迴公式、與體積關係

### 幾何意義
\[
\det(A) = \text{空間體積伸縮的倍數}
\]

- \(|\det A| = 1\)：體積不變  
- \(\det A = 0\)：空間被壓扁（不可逆）

### Laplace 展開（遞迴公式）
\[
\det(A)=\sum_{j=1}^n (-1)^{1+j} a_{1j} M_{1j}
\]

### 與體積的關係
\[
\text{Volume after} = |\det A| \times \text{Volume before}
\]

---

## 6. 對角化如何快速計算行列式

若  
\[
A = P D P^{-1}
\]  
則  
\[
\det(A) = \det(D) = \prod_i \lambda_i
\]

即行列式為所有特徵值的乘積。

---

## 7. LU 分解快速計算行列式

若  
\[
A = LU
\]  
則  
\[
\det(A) = \prod_i u_{ii}
\]

因為 \(L\) 的對角線多為 1。

---

## 8. 特徵值與特徵向量的意義與用途

### 意義
\[
A v = \lambda v
\]  
特徵向量方向不變，特徵值代表伸縮倍數。

### 用途
- 對角化  
- 計算 \(A^n\)  
- Markov 鏈  
- PCA  
- 模式識別  
- 微分方程與物理振動  

---

## 9. QR 分解

\[
A = QR
\]

- \(Q\)：正交矩陣  
- \(R\)：上三角矩陣  

用途：解方程、數值穩定、求特徵值的基礎。

---

## 10. 用 QR 分解求特徵值（QR Algorithm）

重複：

1. \(A_k = Q_k R_k\)
2. \(A_{k+1} = R_k Q_k\)

最終 \(A_k\) 會收斂到上三角矩陣，其對角線即特徵值。

---

## 11. SVD 與特徵值分解的關係

### SVD
\[
A = U \Sigma V^T
\]

- \(U, V\)：正交  
- \(\Sigma\)：奇異值  

### 與特徵值關係
\[
A^T A = V \Sigma^2 V^T
\]

奇異值＝ \(A^T A\) 特徵值的平方根。

---

## 12. PCA 與 SVD 的關係

PCA：找出資料中變異最大的方向（降維）。

資料矩陣 \(X\)：

\[
X = U \Sigma V^T
\]

- \(V\)：主成分方向  
- \(\Sigma\)：變異大小（奇異值）  
- 選取前 k 個奇異值 → k 維 PCA  

---

## License

自由使用於學習、專案或教學。

